{"cells":[{"cell_type":"markdown","metadata":{"id":"MusV5YYT6kQF"},"source":["# 순환 신경망으로 IMDB 리뷰 분류하기"]},{"cell_type":"markdown","metadata":{"id":"9uYfRb5-6kQQ"},"source":["<table align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/9-2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","source":["리뷰 데이터셋은 수집한 리뷰를 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터셋이고 텍스트 데이터의 경우 숫자 데이터로 분리하는데 이렇게 분리된 단어를 토큰이라고 부른다. 하나의 샘플은 여러 개의 토큰으로 이루어져 있고 1개의 토큰이 하나의 타임스텝에 해당"],"metadata":{"id":"-M2RCDQI5FqX"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"dBICoaoYyksi","executionInfo":{"status":"ok","timestamp":1678848449015,"user_tz":-540,"elapsed":353,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["# # 실행마다 동일한 결과를 얻기 위해 케라스에 랜덤 시드를 사용하고 텐서플로 연산을 결정적으로 만듭니다. \n","# import tensorflow as tf\n","\n","# tf.keras.utils.set_random_seed(42)\n","# tf.config.experimental.enable_op_determinism()"]},{"cell_type":"markdown","metadata":{"id":"S1A-DDIQ6kQQ"},"source":["## IMDB 리뷰 데이터셋"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sZoZm1ZO6kQR","executionInfo":{"status":"ok","timestamp":1678848471005,"user_tz":-540,"elapsed":21992,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["from tensorflow.keras.datasets import imdb\n","\n","(train_input, train_target), (test_input, test_target) = imdb.load_data(\n","    num_words=500) # 전체 데이터 셋에서 가장 자주 등장하는 단어 500개만 사용, (당연히 num_words는 패션데이터에서 쓸수 없음)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTFjz6k06kQR","outputId":"586f59dc-a355-4223-aafe-81b1f5987a75","executionInfo":{"status":"ok","timestamp":1678848471006,"user_tz":-540,"elapsed":22,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(25000,) (25000,)\n"]}],"source":["print(train_input.shape, test_input.shape) # 각각 25000개씩 분류 총 5만개샘플"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jMLURzw6kQS","outputId":"4ac2a5e5-41d6-4d3a-b7de-7782db93896d","executionInfo":{"status":"ok","timestamp":1678848471006,"user_tz":-540,"elapsed":21,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["218\n"]}],"source":["print(len(train_input[0])) # 첫 번째 리뷰의 길이"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdO834PL6kQT","outputId":"887c527b-83db-45a4-bb68-4077dcbc98cf","executionInfo":{"status":"ok","timestamp":1678848471007,"user_tz":-540,"elapsed":19,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["189\n"]}],"source":["print(len(train_input[1])) # 두번째 리뷰의 길이"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNuzGQ2c6kQT","outputId":"206f117f-7b36-4817-a466-7c4b2a3de839","executionInfo":{"status":"ok","timestamp":1678848471007,"user_tz":-540,"elapsed":17,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"]}],"source":["print(train_input[0]) # 첫번째 리뷰 내용"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"In8Qzltz6kQT","outputId":"bf7adaa4-68f1-4b59-c977-4b1808a0416a","executionInfo":{"status":"ok","timestamp":1678848471007,"user_tz":-540,"elapsed":16,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"]}],"source":["print(train_target[:20]) # 부정(0)과 긍정(1)로 타깃설정 되어있고 리뷰20개 판단"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0-zjNgBw6kQU","executionInfo":{"status":"ok","timestamp":1678848471493,"user_tz":-540,"elapsed":499,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_input, val_input, train_target, val_target = train_test_split(\n","    train_input, train_target, test_size=0.2, random_state=42) # 검증세트 0.2%"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sRVvgntx6kQU","executionInfo":{"status":"ok","timestamp":1678848471493,"user_tz":-540,"elapsed":5,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["# 평균적인 리뷰와 가장 짧은 길이 그리고 가장 긴 리뷰를 확인\n","import numpy as np \n","lengths = np.array([len(x) for x in train_input]) #(훈련데이터 샘플) 리뷰 길이를 배열로 담기"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p76m_61w6kQU","outputId":"0a2be8ed-6f61-4209-fa45-f1b7ce179c81","executionInfo":{"status":"ok","timestamp":1678848471494,"user_tz":-540,"elapsed":5,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["239.00925 178.0\n"]}],"source":["print(np.mean(lengths), np.median(lengths)) # 리뷰길이 평균, 중간값"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"TVDrsRYF6kQV","outputId":"ca390a5f-3ab9-4bcf-d23d-9c94e263ae77","executionInfo":{"status":"ok","timestamp":1678848471945,"user_tz":-540,"elapsed":456,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","\n","plt.hist(lengths) # 히스토그램으로 리뷰길이 빈도수 확인\n","plt.xlabel('length')\n","plt.ylabel('frequency')\n","plt.show()\n","# 짧은 리뷰가 더 많은 것을 확인"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"fbLSFToP6kQV","executionInfo":{"status":"ok","timestamp":1678848471945,"user_tz":-540,"elapsed":13,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["# 예제에서는 중간값보다 훨씬 짧은 100개의 단어만 사용. 하지만 100개보다 작은 리뷰가 있는데 이 길이를 맞추기 위해 패딩을 사용하고\n","# 패딩을 나타내는 토큰으로는 0을 사용 \n","# >> 위 작업을 편리하게 해주는 클래스사용 \n","from tensorflow.keras.preprocessing.sequence import pad_sequences \n","\n","train_seq = pad_sequences(train_input, maxlen=100) "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c86x0Yj6kQV","outputId":"b093dc5a-9368-44c1-d28c-e9841beb1d4a","executionInfo":{"status":"ok","timestamp":1678848471946,"user_tz":-540,"elapsed":13,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 100)\n"]}],"source":["print(train_seq.shape) # 각 20000개 샘플의 길이100 >> 2차원 배열"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JuP0QJaU6kQW","outputId":"b51e2619-169a-4899-85a4-07dffc25a1fa","executionInfo":{"status":"ok","timestamp":1678848471946,"user_tz":-540,"elapsed":11,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n","   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n","  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n","   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n","   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n","   6   2  46   7  14  20  10  10 470 158]\n"]}],"source":["print(train_seq[0]) # 첫번째 샘플의 내용"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6t8kaDji6kQW","outputId":"145481de-dc15-4801-a66f-d5a9f9b86c23","executionInfo":{"status":"ok","timestamp":1678848471946,"user_tz":-540,"elapsed":10,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"]}],"source":["print(train_input[0][-10:]) "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Emmoztwa6kQX","outputId":"bfdbeb87-96cc-47e2-ebc0-31c950bb98e9","scrolled":true,"executionInfo":{"status":"ok","timestamp":1678848471947,"user_tz":-540,"elapsed":10,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n","  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n","   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n","   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n","  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n","   2   2 290   2  46  48  64  18   4   2]\n"]}],"source":["print(train_seq[5])"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ZeFmsjOd6kQX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678848471947,"user_tz":-540,"elapsed":9,"user":{"displayName":"권성재","userId":"07443728884847841905"}},"outputId":"519a6be4-7182-432d-9c7c-e5884f299934"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 32   2 225 ...  14  58   2]\n"," [ 53   2   8 ...   7  32   2]\n"," [  0   0   0 ...   2  33  32]\n"," ...\n"," [383   2 120 ...  16  99  76]\n"," [106 345  12 ... 120   2 156]\n"," [  4 114  21 ...   4   2   2]]\n"]}],"source":["val_seq = pad_sequences(val_input, maxlen=100) # 5000개의 샘플을 길이100으로 변환\n","print(val_seq)"]},{"cell_type":"markdown","metadata":{"id":"9xab0nu_6kQX"},"source":["## 순환 신경망 만들기"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"45BtHGKX6kQX","executionInfo":{"status":"ok","timestamp":1678848472239,"user_tz":-540,"elapsed":299,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["from tensorflow import keras\n","\n","model = keras.Sequential() # 인공 신경망 객체 모델 생성\n","\n","model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500))) # 순환층 클래스(뉴런의 개수, input_shape(샘플의 길이100, 500), activation기본값= tnah)\n","model.add(keras.layers.Dense(1, activation='sigmoid')) # 이진분류이므로 마지막 출력층은 1개의 뉴런을 가지고 시그모이드 활성화 함수를 사용"]},{"cell_type":"markdown","source":["토근을 정수로 변환한 이 데이터를 신경망에 주입하면 큰 정수가 큰 활성화 출력을 만드는데 이 정수 사이에는 분명 어떠한 관련도 없고 없어야됨. \n",">> 따라서 단순한 정수값을 신경망에 입력하기 위해 각 고유한 정수를 표현하는 원-핫 인코딩이 필요"],"metadata":{"id":"nuq4fukP-OyR"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"oXIWyOuw6kQY","executionInfo":{"status":"ok","timestamp":1678848477940,"user_tz":-540,"elapsed":5704,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["train_oh = keras.utils.to_categorical(train_seq) # 원-핫 인코딩 (훈련세트)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD94WiRT6kQY","outputId":"824833ee-9bf6-4ce3-f725-5c8c06916c61","executionInfo":{"status":"ok","timestamp":1678848477940,"user_tz":-540,"elapsed":7,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 100, 500)\n"]}],"source":["print(train_oh.shape) # 정수 하나마다 모두 500차원의 배열로 변경 되었기 때문에 위에 input_shpae 매개변수 값을 100,200으로 지정한 것임"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIVSHwJg6kQY","outputId":"450ddb97-e38d-42e7-a895-f817526412c0","executionInfo":{"status":"ok","timestamp":1678848477940,"user_tz":-540,"elapsed":6,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"]}],"source":["print(train_oh[0][0][:12]) # 첫번째 샘플의 첫번째 단어(토큰)의 인코딩?"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CP3ivii46kQZ","outputId":"c8e2b969-896e-49f8-f839-a4148fe10fe8","executionInfo":{"status":"ok","timestamp":1678848477940,"user_tz":-540,"elapsed":4,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}],"source":["print(np.sum(train_oh[0][0])) # 첫번째 샘플의 첫번째 단어(토큰)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"vgijH6m26kQZ","executionInfo":{"status":"ok","timestamp":1678848479109,"user_tz":-540,"elapsed":1171,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[],"source":["\n","val_oh = keras.utils.to_categorical(val_seq) # (검증세트도 변환)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0V0Svpuf6kQZ","outputId":"8958b1df-f4a7-42ea-97f1-6237fb53b0a5","executionInfo":{"status":"ok","timestamp":1678848479499,"user_tz":-540,"elapsed":393,"user":{"displayName":"권성재","userId":"07443728884847841905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 8)                 4072      \n","                                                                 \n"," dense (Dense)               (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 4,081\n","Trainable params: 4,081\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary() \n","# 순환층에 전달할 샘플의 크기는 (100,200)이지만 이 순환층은 마지막 타임스텝의 은닉 상태만 출력하기 때문에\n","# 출력크기가 순환층의 뉴런개수와 동일 8개\n","\n","# 500차원의 원-핫 인코딩 배열과 8개 뉴런이 완전히 연결 되었기 때문에 4000개의 가중치가 있고 \n","# 순환층의 은닉 상태는 다시 타음스텝에 사용되기 위해 8*8 =64개의 가중치가 필요하고 \n","# 뉴런8개 마다 하나의 절편이 있어 \n","# 총 4081개의 모델 파라미터가 필요"]},{"cell_type":"markdown","metadata":{"id":"S22Hc-7L6kQZ"},"source":["## 순환 신경망 훈련하기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcwM299t6kQZ","outputId":"8a16e402-1b67-4b3d-f72f-008447b81da7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","313/313 [==============================] - 31s 85ms/step - loss: 0.6984 - accuracy: 0.5120 - val_loss: 0.6950 - val_accuracy: 0.5174\n","Epoch 2/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.6929 - accuracy: 0.5220 - val_loss: 0.6914 - val_accuracy: 0.5274\n","Epoch 3/100\n","313/313 [==============================] - 17s 55ms/step - loss: 0.6894 - accuracy: 0.5313 - val_loss: 0.6887 - val_accuracy: 0.5342\n","Epoch 4/100\n","313/313 [==============================] - 17s 53ms/step - loss: 0.6863 - accuracy: 0.5443 - val_loss: 0.6863 - val_accuracy: 0.5412\n","Epoch 5/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.6832 - accuracy: 0.5565 - val_loss: 0.6838 - val_accuracy: 0.5520\n","Epoch 6/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.6799 - accuracy: 0.5688 - val_loss: 0.6808 - val_accuracy: 0.5590\n","Epoch 7/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.6758 - accuracy: 0.5803 - val_loss: 0.6767 - val_accuracy: 0.5770\n","Epoch 8/100\n","313/313 [==============================] - 16s 50ms/step - loss: 0.6701 - accuracy: 0.5958 - val_loss: 0.6692 - val_accuracy: 0.5978\n","Epoch 9/100\n","313/313 [==============================] - 16s 52ms/step - loss: 0.6581 - accuracy: 0.6237 - val_loss: 0.6499 - val_accuracy: 0.6316\n","Epoch 10/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.6142 - accuracy: 0.6788 - val_loss: 0.6014 - val_accuracy: 0.6858\n","Epoch 11/100\n","313/313 [==============================] - 17s 53ms/step - loss: 0.5880 - accuracy: 0.7006 - val_loss: 0.5913 - val_accuracy: 0.6954\n","Epoch 12/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.5739 - accuracy: 0.7157 - val_loss: 0.5787 - val_accuracy: 0.7102\n","Epoch 13/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.5612 - accuracy: 0.7253 - val_loss: 0.5667 - val_accuracy: 0.7192\n","Epoch 14/100\n","313/313 [==============================] - 18s 58ms/step - loss: 0.5489 - accuracy: 0.7358 - val_loss: 0.5552 - val_accuracy: 0.7294\n","Epoch 15/100\n","313/313 [==============================] - 17s 55ms/step - loss: 0.5389 - accuracy: 0.7425 - val_loss: 0.5459 - val_accuracy: 0.7356\n","Epoch 16/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.5281 - accuracy: 0.7519 - val_loss: 0.5385 - val_accuracy: 0.7400\n","Epoch 17/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.5176 - accuracy: 0.7588 - val_loss: 0.5273 - val_accuracy: 0.7432\n","Epoch 18/100\n","313/313 [==============================] - 15s 47ms/step - loss: 0.5087 - accuracy: 0.7638 - val_loss: 0.5206 - val_accuracy: 0.7486\n","Epoch 19/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.4998 - accuracy: 0.7705 - val_loss: 0.5128 - val_accuracy: 0.7532\n","Epoch 20/100\n","313/313 [==============================] - 15s 47ms/step - loss: 0.4914 - accuracy: 0.7753 - val_loss: 0.5072 - val_accuracy: 0.7596\n","Epoch 21/100\n","313/313 [==============================] - 17s 54ms/step - loss: 0.4842 - accuracy: 0.7814 - val_loss: 0.5052 - val_accuracy: 0.7604\n","Epoch 22/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.4781 - accuracy: 0.7842 - val_loss: 0.5000 - val_accuracy: 0.7620\n","Epoch 23/100\n","313/313 [==============================] - 16s 51ms/step - loss: 0.4717 - accuracy: 0.7883 - val_loss: 0.4946 - val_accuracy: 0.7668\n","Epoch 24/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.4658 - accuracy: 0.7925 - val_loss: 0.4907 - val_accuracy: 0.7698\n","Epoch 25/100\n","313/313 [==============================] - 16s 52ms/step - loss: 0.4610 - accuracy: 0.7954 - val_loss: 0.4881 - val_accuracy: 0.7700\n","Epoch 26/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.4563 - accuracy: 0.7974 - val_loss: 0.4864 - val_accuracy: 0.7760\n","Epoch 27/100\n","313/313 [==============================] - 16s 52ms/step - loss: 0.4519 - accuracy: 0.8001 - val_loss: 0.4832 - val_accuracy: 0.7758\n","Epoch 28/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.4474 - accuracy: 0.8026 - val_loss: 0.4825 - val_accuracy: 0.7770\n","Epoch 29/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.4444 - accuracy: 0.8030 - val_loss: 0.4783 - val_accuracy: 0.7774\n","Epoch 30/100\n","313/313 [==============================] - 17s 53ms/step - loss: 0.4401 - accuracy: 0.8072 - val_loss: 0.4793 - val_accuracy: 0.7782\n","Epoch 31/100\n","313/313 [==============================] - 15s 49ms/step - loss: 0.4376 - accuracy: 0.8088 - val_loss: 0.4767 - val_accuracy: 0.7794\n","Epoch 32/100\n","313/313 [==============================] - 16s 52ms/step - loss: 0.4353 - accuracy: 0.8102 - val_loss: 0.4740 - val_accuracy: 0.7812\n","Epoch 33/100\n","313/313 [==============================] - 16s 52ms/step - loss: 0.4329 - accuracy: 0.8101 - val_loss: 0.4742 - val_accuracy: 0.7826\n","Epoch 34/100\n","313/313 [==============================] - 16s 53ms/step - loss: 0.4309 - accuracy: 0.8105 - val_loss: 0.4769 - val_accuracy: 0.7800\n","Epoch 35/100\n","313/313 [==============================] - 16s 50ms/step - loss: 0.4280 - accuracy: 0.8129 - val_loss: 0.4721 - val_accuracy: 0.7808\n","Epoch 36/100\n","313/313 [==============================] - 15s 47ms/step - loss: 0.4258 - accuracy: 0.8135 - val_loss: 0.4730 - val_accuracy: 0.7824\n","Epoch 37/100\n","313/313 [==============================] - 15s 47ms/step - loss: 0.4244 - accuracy: 0.8146 - val_loss: 0.4809 - val_accuracy: 0.7772\n","Epoch 38/100\n","313/313 [==============================] - 15s 48ms/step - loss: 0.4224 - accuracy: 0.8171 - val_loss: 0.4710 - val_accuracy: 0.7820\n","Epoch 39/100\n","313/313 [==============================] - 16s 49ms/step - loss: 0.4211 - accuracy: 0.8170 - val_loss: 0.4721 - val_accuracy: 0.7836\n","Epoch 40/100\n","313/313 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.8185"]}],"source":["rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n","model.compile(optimizer=rmsprop, loss='binary_crossentropy', # rmsprop옵티마이저, 손실함수=이진분류, 정확도표기\n","              metrics=['accuracy'])\n","\n","# 체크포인트와 조기 종료를 구성하는 코드\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5', \n","                                                save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, \n","                                                  restore_best_weights=True)\n","\n","# 순환클래스 모델 훈련\n","history = model.fit(train_oh, train_target, epochs=100, batch_size=64,\n","                    validation_data=(val_oh, val_target),\n","                    callbacks=[checkpoint_cb, early_stopping_cb])\n","\n","# 80프로의 성능을 보여줌"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YS_5tIG26kQa"},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()\n","# 검증세트의 손실감소가 둔해지는 구간 에포크 지점 확인"]},{"cell_type":"markdown","metadata":{"id":"K_U_lVie6kQa"},"source":["## 단어 임베딩을 사용하기\n","\n","순환 신경망에서 텍스트를 처리할 때 즐겨 사용하는 방법으로 단어 임베딩이 있는데 각 다너를 고정된 크기의 실수 벡터로 바꾸어 준다.\n","이런 단어 임베딩으로 만들어진 벡터는 원-핫인코딩 된 벡터보다 후러씬 의미 있는 값으로 채워져 자연어 처리에서 더 좋은 성능을 내는 경우가 있음."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ofl-Ifev6kQa"},"outputs":[],"source":["model2 = keras.Sequential() \n","\n","# 단어 임베딩 층을 제공하는 Embedding클래스(), 첫번째 매객변수 500은 어휘 사전의 크기지정<< 앞서 리뷰데이터셋에서 단어500개만 사용하도록 설정했기 때문에 지정\n","# 두번째 매개변수는 임베딩 벡터 크기, 세번째는 샘플 데이터 길이\n","model2.add(keras.layers.Embedding(500, 16, input_length=100))  \n","model2.add(keras.layers.SimpleRNN(8)) # 순환층 클래스(뉴런의 개수, activation기본값= tnah)\n","model2.add(keras.layers.Dense(1, activation='sigmoid')) # 출력층 \n","\n","model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78TUrJAs6kQa"},"outputs":[],"source":["# 모델 컴파일\n","rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n","model2.compile(optimizer=rmsprop, loss='binary_crossentropy', \n","               metrics=['accuracy'])\n","\n","# 체크포인트와 조기종료\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', \n","                                                save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n","                                                  restore_best_weights=True)\n","\n","# 모델2 훈련\n","history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n","                     validation_data=(val_seq, val_target),\n","                     callbacks=[checkpoint_cb, early_stopping_cb])\n","# 결과를 보명 원-핫 인코딩을 사용한 모델과 원-핫 인코딩을 사용하지 않은 train_seq과 val_seq을 이용한 임베딩 방법은\n","# 비슷한 성능을 내지만 순환층의 가중치개수는 훨찍 작고 훈련 세트 크기도 줄음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brUvKwLt6kQb","tags":[]},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()\n","# 검증손실은 특정 부분에서 더 이상 감소가 일어나지 않아 조기종료 되었고 훈련손실은 계속 진행됨"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}